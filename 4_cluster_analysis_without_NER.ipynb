{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "4.cluster_analysis without NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SanjayMarreddi/Creating-summary-and-knowledge-graph-from-News-Articles/blob/master/4_cluster_analysis_without_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRGGBCtgP-0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "import codecs\n",
        "from sklearn import feature_extraction\n",
        "import mpld3\n",
        "from newspaper import Article\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yylx9hNsP-1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article = pd.read_csv('sample_data.csv')\n",
        "article.columns = ['idx','tags','text','genre','cluster']\n",
        "article = article.head(100)\n",
        "article = article.dropna()\n",
        "article.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfHyCIGvP-2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import three lists: titles, links and wikipedia synopses\n",
        "titles = article.tags.tolist()\n",
        "\n",
        "synopses = article.text.tolist()\n",
        "    \n",
        "genres = article.genre.tolist()\n",
        "# print (genres)\n",
        "print(str(len(titles)) + ' titles')\n",
        "print(str(len(synopses)) + ' synopses')\n",
        "print(str(len(genres)) + ' genres')\n",
        "# synopses[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd1ffe12P-3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generates index for each item in the corpora (in this case it's just rank) and I'll use this for scoring later\n",
        "ranks = []\n",
        "\n",
        "for i in range(0,len(titles)):\n",
        "    ranks.append(i)\n",
        "\n",
        "# ranks[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JopqjTpP-30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load nltk's English stopwords as variable called 'stopwords'\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePivfGaUP-4r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBDHd8GYP-5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
        "\n",
        "def tokenize_and_stem(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "    return stems\n",
        "\n",
        "\n",
        "def tokenize_only(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    return filtered_tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_7maPTFP-9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "totalvocab_stemmed = []\n",
        "totalvocab_tokenized = []\n",
        "for i in synopses:\n",
        "    allwords_stemmed = tokenize_and_stem(i)\n",
        "    totalvocab_stemmed.extend(allwords_stemmed)\n",
        "    \n",
        "    allwords_tokenized = tokenize_only(i)\n",
        "    totalvocab_tokenized.extend(allwords_tokenized)\n",
        "\n",
        "# totalvocab_stemmed[0]\n",
        "# totalvocab_tokenized[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg81jkPeP--J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
        "# vocab_frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glQE_jBfP-_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# tfidf -> term frequency Inversing the Index\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=20000,\n",
        "                                 min_df=0.1, stop_words='english',\n",
        "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
        "\n",
        "# ngram is useful for taking Previous and later tokens for analysing each token here (1,3) means this   \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGzqgmqsP_AV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf_matrix = tfidf_vectorizer.fit_transform(synopses)\n",
        "\n",
        "print(tfidf_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulxCBuXwP_B6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terms = tfidf_vectorizer.get_feature_names()\n",
        "# terms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN-VC9BYP_Cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "dist = 1 - cosine_similarity(tfidf_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jq7Gi8BxP_Dd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "num_clusters = 5\n",
        "\n",
        "km = KMeans(n_clusters=num_clusters)\n",
        "\n",
        "km.fit(tfidf_matrix)\n",
        "\n",
        "clusters = km.labels_.tolist()\n",
        "len(clusters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0vihHIuP_EE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(titles))\n",
        "print(len(ranks))\n",
        "print(len(synopses))\n",
        "print(len(clusters))\n",
        "print(len(genres))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_To-SI-P_E1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "articles = { 'title': titles, 'rank': ranks, 'synopsis': synopses, 'cluster': clusters, 'genre': genres }\n",
        "#print(articles)\n",
        "frame = pd.DataFrame(articles, index = [clusters], columns = ['rank', 'title', 'cluster', 'genre'])\n",
        "frame.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLPceMeHP_Fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "frame['cluster'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m13sfiB3P_Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grouped = frame['rank'].groupby(frame['cluster'])\n",
        "\n",
        "grouped.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXfqSzAKP_Hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "print(\"Top terms per cluster:\")\n",
        "print()\n",
        "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
        "for i in range(num_clusters):\n",
        "    print(\"Cluster %d words:\" % i, end='')\n",
        "    for ind in order_centroids[i, :6]:\n",
        "        print(' %s' % vocab_frame.ix[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
        "    print()\n",
        "    print()\n",
        "    print(\"Cluster %d titles:\" % i, end='')\n",
        "    for title in frame.ix[i]['title'].values.tolist():\n",
        "        print(' %s,' % title, end='')\n",
        "    print()\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ZEqAseP_IO",
        "colab_type": "text"
      },
      "source": [
        "# Multidimensional scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ2gFlw-P_Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os  # for os.path.basename\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "from sklearn.manifold import MDS\n",
        "\n",
        "MDS()\n",
        "\n",
        "# two components as we're plotting points in a two-dimensional plane\n",
        "# \"precomputed\" because we provide a distance matrix\n",
        "# we will also specify `random_state` so the plot is reproducible.\n",
        "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
        "\n",
        "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
        "\n",
        "xs, ys = pos[:, 0], pos[:, 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbx3Ec1AP_JD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#strip any proper nouns (NNP) or plural proper nouns (NNPS) from a text\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "def strip_proppers_POS(text):\n",
        "    tagged = pos_tag(text.split()) #use NLTK's part of speech tagger\n",
        "    non_propernouns = [word for word,pos in tagged if pos != 'NNP' and pos != 'NNPS']\n",
        "    return non_propernouns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2JdHtSvP_J_",
        "colab_type": "text"
      },
      "source": [
        "## Visualizing document clusters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKjKjEZ9P_KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set up colors per clusters using a dict\n",
        "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}\n",
        "\n",
        "#set up cluster names using a dict\n",
        "cluster_names = {0: 'Trump, Hillary', \n",
        "                 1: 'Police, killed, murders', \n",
        "                 2: 'Father, New York, brothers', \n",
        "                 3: 'Dance, singing, love', \n",
        "                 4: 'Killed, soldiers, captain'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WXnIrr6P_Kq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35oBavLQP_LB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
        "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=titles)) \n",
        "\n",
        "#group by cluster\n",
        "groups = df.groupby('label')\n",
        "\n",
        "\n",
        "# set up plot\n",
        "# fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
        "# ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
        "\n",
        "# #iterate through groups to layer the plot\n",
        "# #note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
        "# for name, group in groups:\n",
        "#     ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=cluster_names[name], color=cluster_colors[name], mec='none')\n",
        "#     ax.set_aspect('auto')\n",
        "#     ax.tick_params(\\\n",
        "#         axis= 'x',          # changes apply to the x-axis\n",
        "#         which='both',      # both major and minor ticks are affected\n",
        "#         bottom='off',      # ticks along the bottom edge are off\n",
        "#         top='off',         # ticks along the top edge are off\n",
        "#         labelbottom='off')\n",
        "#     ax.tick_params(\\\n",
        "#         axis= 'y',         # changes apply to the y-axis\n",
        "#         which='both',      # both major and minor ticks are affected\n",
        "#         left='off',      # ticks along the bottom edge are off\n",
        "#         top='off',         # ticks along the top edge are off\n",
        "#         labelleft='off')\n",
        "    \n",
        "# ax.legend(numpoints=1)  #show legend with only 1 point\n",
        "\n",
        "# #add label in x,y position with the label as the film title\n",
        "# for i in range(len(df)):\n",
        "#     ax.text(df.ix[i]['x'], df.ix[i]['y'], df.ix[i]['title'], size=8)  \n",
        "\n",
        "    \n",
        "    \n",
        "# plt.show() #show the plot\n",
        "\n",
        "#uncomment the below to save the plot if need be\n",
        "#plt.savefig('clusters_small_noaxes.png', dpi=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lJTSAv9P_Lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define custom toolbar location\n",
        "class TopToolbar(mpld3.plugins.PluginBase):\n",
        "    \"\"\"Plugin for moving toolbar to top of figure\"\"\"\n",
        "\n",
        "    JAVASCRIPT = \"\"\"\n",
        "    mpld3.register_plugin(\"toptoolbar\", TopToolbar);\n",
        "    TopToolbar.prototype = Object.create(mpld3.Plugin.prototype);\n",
        "    TopToolbar.prototype.constructor = TopToolbar;\n",
        "    function TopToolbar(fig, props){\n",
        "        mpld3.Plugin.call(this, fig, props);\n",
        "    };\n",
        "\n",
        "    TopToolbar.prototype.draw = function(){\n",
        "      // the toolbar svg doesn't exist\n",
        "      // yet, so first draw it\n",
        "      this.fig.toolbar.draw();\n",
        "\n",
        "      // then change the y position to be\n",
        "      // at the top of the figure\n",
        "      this.fig.toolbar.toolbar.attr(\"x\", 150);\n",
        "      this.fig.toolbar.toolbar.attr(\"y\", 400);\n",
        "\n",
        "      // then remove the draw function,\n",
        "      // so that it is not called again\n",
        "      this.fig.toolbar.draw = function() {}\n",
        "    }\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.dict_ = {\"type\": \"toptoolbar\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WVb7koyP_MU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
        "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=titles)) \n",
        "\n",
        "#group by cluster\n",
        "groups = df.groupby('label')\n",
        "\n",
        "#define custom css to format the font and to remove the axis labeling\n",
        "css = \"\"\"\n",
        "text.mpld3-text, div.mpld3-tooltip {\n",
        "  font-family:Arial, Helvetica, sans-serif;\n",
        "}\n",
        "\n",
        "g.mpld3-xaxis, g.mpld3-yaxis {\n",
        "display: none; }\n",
        "\"\"\"\n",
        "\n",
        "# Plot \n",
        "fig, ax = plt.subplots(figsize=(14,6)) #set plot size\n",
        "ax.margins(0.03) # Optional, just adds 5% padding to the autoscaling\n",
        "\n",
        "#iterate through groups to layer the plot\n",
        "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
        "for name, group in groups:\n",
        "    points = ax.plot(group.x, group.y, marker='o', linestyle='', ms=18, label=cluster_names[name], mec='none', color=cluster_colors[name])\n",
        "    ax.set_aspect('auto')\n",
        "    labels = [i for i in group.title]\n",
        "    \n",
        "    #set tooltip using points, labels and the already defined 'css'\n",
        "    tooltip = mpld3.plugins.PointHTMLTooltip(points[0], labels,\n",
        "                                       voffset=10, hoffset=10, css=css)\n",
        "    #connect tooltip to fig\n",
        "    mpld3.plugins.connect(fig, tooltip, TopToolbar())    \n",
        "    \n",
        "    #set tick marks as blank\n",
        "    ax.axes.get_xaxis().set_ticks([])\n",
        "    ax.axes.get_yaxis().set_ticks([])\n",
        "    \n",
        "    #set axis as blank\n",
        "    ax.axes.get_xaxis().set_visible(False)\n",
        "    ax.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    \n",
        "ax.legend(numpoints=1) #show legend with only one dot\n",
        "\n",
        "mpld3.display() #show the plot\n",
        "\n",
        "#uncomment the below to export to html\n",
        "#html = mpld3.fig_to_html(fig)\n",
        "#print(html)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa44m2a3P_Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}